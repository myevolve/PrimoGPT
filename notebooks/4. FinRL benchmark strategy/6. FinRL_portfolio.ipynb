{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FinRL and stable_baselines3 for machine learning and trading\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_primo_trading.env_primo_default import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# Configuration files and helper functions from FinRL\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.main import check_and_make_directories\n",
    "\n",
    "# Enabling chart display within Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "TRAINED_MODEL_DIR = 'files/models_PORTFOLIO'\n",
    "RESULTS_DIR = 'files/results_PORTFOLIO'\n",
    "DATA_DIR = 'files/data_PORTFOLIO'\n",
    "\n",
    "# Checking and creating directories\n",
    "check_and_make_directories([TRAINED_MODEL_DIR, DATA_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and trading intervals\n",
    "TRAIN_START_DATE = '2022-04-01'\n",
    "TRAIN_END_DATE = '2024-07-31'\n",
    "TRADE_START_DATE = '2024-08-01'\n",
    "TRADE_END_DATE = '2025-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (3645, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetching all data\n",
    "df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                         end_date = TRADE_END_DATE,\n",
    "                         ticker_list = [\"AAPL\", \"NFLX\", \"MSFT\", \"CRM\", \"AMZN\"]).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>171.530609</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>174.880005</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>78751300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>165.826996</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>57090000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>211.071075</td>\n",
       "      <td>212.250000</td>\n",
       "      <td>214.029999</td>\n",
       "      <td>212.479996</td>\n",
       "      <td>6007900</td>\n",
       "      <td>CRM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>301.616882</td>\n",
       "      <td>309.420013</td>\n",
       "      <td>310.130005</td>\n",
       "      <td>309.369995</td>\n",
       "      <td>27110500</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>373.470001</td>\n",
       "      <td>373.470001</td>\n",
       "      <td>380.869995</td>\n",
       "      <td>376.799988</td>\n",
       "      <td>4644200</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume   tic  \\\n",
       "0  2022-04-01  171.530609  174.309998  174.880005  174.029999  78751300  AAPL   \n",
       "1  2022-04-01  163.559998  163.559998  165.826996  164.149506  57090000  AMZN   \n",
       "2  2022-04-01  211.071075  212.250000  214.029999  212.479996   6007900   CRM   \n",
       "3  2022-04-01  301.616882  309.420013  310.130005  309.369995  27110500  MSFT   \n",
       "4  2022-04-01  373.470001  373.470001  380.869995  376.799988   4644200  NFLX   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    4  \n",
       "4    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (728, 8)\n",
      "Successfully added vix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_vix=True,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of unique stock tickers from the 'tic' column of the 'processed' DataFrame.\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creates a list of dates between the earliest and latest dates in the 'processed' DataFrame, converting them to strings.\n",
    "list_date = list(pd.date_range(processed['date'].min(), processed['date'].max()).astype(str))\n",
    "\n",
    "# Creates combinations of all dates and stock tickers using the Cartesian product.\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "# Creates a new DataFrame 'processed_full' with columns \"date\" and \"tic\", containing all combinations of dates and stock tickers.\n",
    "# Merges this DataFrame with the original 'processed' DataFrame based on the \"date\" and \"tic\" columns, using a 'left' join.\n",
    "processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"]).merge(processed, on=[\"date\", \"tic\"], how=\"left\")\n",
    "\n",
    "# Filters the 'processed_full' DataFrame to contain only those rows whose dates are present in the original 'processed' DataFrame.\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Sorts the 'processed_full' DataFrame by date and stock ticker.\n",
    "processed_full = processed_full.sort_values(['date', 'tic'])\n",
    "\n",
    "# Replaces all missing values (NaN) with 0 in the 'processed_full' DataFrame.\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>171.530609</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>174.880005</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>78751300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.06369</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>165.826996</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>57090000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.06369</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>CRM</td>\n",
       "      <td>211.071075</td>\n",
       "      <td>212.250000</td>\n",
       "      <td>214.029999</td>\n",
       "      <td>212.479996</td>\n",
       "      <td>6007900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.06369</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>212.479996</td>\n",
       "      <td>212.479996</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>301.616882</td>\n",
       "      <td>309.420013</td>\n",
       "      <td>310.130005</td>\n",
       "      <td>309.369995</td>\n",
       "      <td>27110500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.06369</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>309.369995</td>\n",
       "      <td>309.369995</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>373.470001</td>\n",
       "      <td>373.470001</td>\n",
       "      <td>380.869995</td>\n",
       "      <td>376.799988</td>\n",
       "      <td>4644200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.06369</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>376.799988</td>\n",
       "      <td>376.799988</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2022-04-01  AAPL  171.530609  174.309998  174.880005  174.029999   \n",
       "1  2022-04-01  AMZN  163.559998  163.559998  165.826996  164.149506   \n",
       "2  2022-04-01   CRM  211.071075  212.250000  214.029999  212.479996   \n",
       "3  2022-04-01  MSFT  301.616882  309.420013  310.130005  309.369995   \n",
       "4  2022-04-01  NFLX  373.470001  373.470001  380.869995  376.799988   \n",
       "\n",
       "       volume  day  macd    boll_ub     boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  78751300.0  4.0   0.0  175.06369  173.536316   100.0  66.666667  100.0   \n",
       "1  57090000.0  4.0   0.0  175.06369  173.536316   100.0  66.666667  100.0   \n",
       "2   6007900.0  4.0   0.0  175.06369  173.536316   100.0  66.666667  100.0   \n",
       "3  27110500.0  4.0   0.0  175.06369  173.536316   100.0  66.666667  100.0   \n",
       "4   4644200.0  4.0   0.0  175.06369  173.536316   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma        vix  turbulence  \n",
       "0    174.029999    174.029999  20.620001         0.0  \n",
       "1    164.149506    164.149506  20.620001         0.0  \n",
       "2    212.479996    212.479996  20.620001         0.0  \n",
       "3    309.369995    309.369995  20.620001         0.0  \n",
       "4    376.799988    376.799988  20.620001         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "715\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training and trade set according to the defined dates\n",
    "train = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE, TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "train.to_csv('train_data.csv')\n",
    "trade.to_csv('trade_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 5, State Space: 51\n"
     ]
    }
   ],
   "source": [
    "# Calculating the dimension (number of unique stocks) from the 'train' DataFrame.\n",
    "stock_dimension = len(train.tic.unique())\n",
    "\n",
    "# Calculating the size of the state based on the dimension and the number of technical indicators.\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates lists of buy and sell costs for each stock.\n",
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "\n",
    "# Initializes the number of shares for each stock to 0.\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "# Define arguments for the trading environment.\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,  # Maximum number of shares that can be bought or sold in a single transaction.\n",
    "    \"initial_amount\": 100000,  # Initial amount of capital.\n",
    "    \"num_stock_shares\": num_stock_shares,  # Initial number of shares for each stock in the portfolio, initially set to 0.\n",
    "    \"buy_cost_pct\": buy_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"sell_cost_pct\": sell_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"state_space\": state_space,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"stock_dim\": stock_dimension,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"tech_indicator_list\": INDICATORS,  # List of technical indicators to be used for market state analysis.\n",
    "    \"action_space\": stock_dimension,  # Size of the action space, i.e., the number of different actions the model can take.\n",
    "    \"reward_scaling\": 1e-2  # Scaling factor for the reward, used to adjust the reward size to facilitate learning.\n",
    "}\n",
    "\n",
    "# Create the training environment.\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "# Retrieve the environment suitable for Stable Baselines and the unused object.\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training DRL Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DRL agent with the provided training environment.\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "# Set the appropriate values to 'True' for the algorithms you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 5 different DRL agents (A2C, DDPG, PPO, TD3, SAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to files/results_PORTFOLIO/a2c\n"
     ]
    }
   ],
   "source": [
    "# A new instance of the DRL agent is created with the provided environment (it is not necessary to do this again, but for easier instructions, it remains)\n",
    "agent = DRLAgent(env = env_train)\n",
    "# Retrieves the A2C model using the get_model method\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # Setting up the logger to monitor and record information during training\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  # Configures a new logger that will print information to standard output, save to a CSV file, and TensorBoard\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Sets the new logger for the A2C model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1029       |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0.0182     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | 102        |\n",
      "|    reward             | -17.095575 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 429        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 975        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -0.044     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 20.5       |\n",
      "|    reward             | -0.6593971 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 45         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1042      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.16     |\n",
      "|    explained_variance | 0.0503    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -222      |\n",
      "|    reward             | 17.629217 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.73e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1046       |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.17      |\n",
      "|    explained_variance | -0.0183    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 140        |\n",
      "|    reward             | 0.92800295 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 571        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 957      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.18    |\n",
      "|    explained_variance | 0.0028   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 232      |\n",
      "|    reward             | 8.65199  |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 2.89e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 951       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.18     |\n",
      "|    explained_variance | 0.0158    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 128       |\n",
      "|    reward             | 15.634208 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 314       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 936        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.17      |\n",
      "|    explained_variance | -0.0121    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -48.9      |\n",
      "|    reward             | -1.0439758 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 130        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 947        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.17      |\n",
      "|    explained_variance | 0.0371     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -16.6      |\n",
      "|    reward             | -11.685258 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 282        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 959       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.19     |\n",
      "|    explained_variance | -0.0167   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 275       |\n",
      "|    reward             | 18.705252 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.52e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 967       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.2      |\n",
      "|    explained_variance | 0.009     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 148       |\n",
      "|    reward             | 1.6785545 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.06e+03  |\n",
      "-------------------------------------\n",
      "day: 583, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170699.47\n",
      "total_reward: 70699.47\n",
      "total_cost: 0.00\n",
      "total_trades: 2113\n",
      "Sharpe: 0.847\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 973        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.2       |\n",
      "|    explained_variance | 0.00869    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 161        |\n",
      "|    reward             | -2.0680053 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 577        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 978      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.23    |\n",
      "|    explained_variance | 0.0229   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 276      |\n",
      "|    reward             | 6.973761 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 1.66e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 983       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | -0.00222  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -73.3     |\n",
      "|    reward             | 25.997715 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 773       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 987       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.23     |\n",
      "|    explained_variance | -0.0213   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -277      |\n",
      "|    reward             | -34.95637 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.75e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 990      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.26    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -17.3    |\n",
      "|    reward             | 5.364284 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 85.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 993       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.26     |\n",
      "|    explained_variance | -0.0194   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 164       |\n",
      "|    reward             | 1.3580447 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.1e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 994       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 164       |\n",
      "|    reward             | 76.09766  |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 604       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 993      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.31    |\n",
      "|    explained_variance | -0.00151 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -198     |\n",
      "|    reward             | 34.5897  |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 827      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 988        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | -0.295     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -151       |\n",
      "|    reward             | -1.9228947 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 524        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 980      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.32    |\n",
      "|    explained_variance | -0.00295 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 45.7     |\n",
      "|    reward             | 2.85122  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 116      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 974      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.33    |\n",
      "|    explained_variance | -0.015   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 132      |\n",
      "|    reward             | -7.4025  |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 451      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 976       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -59.4     |\n",
      "|    reward             | 31.126736 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 593       |\n",
      "-------------------------------------\n",
      "day: 583, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 150073.93\n",
      "total_reward: 50073.93\n",
      "total_cost: 0.00\n",
      "total_trades: 1800\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 970       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 1.9e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 199       |\n",
      "|    reward             | 7.2416973 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 923       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 968       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 90.5      |\n",
      "|    reward             | 6.6885333 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 610       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 965       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | 0.0019    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -40.9     |\n",
      "|    reward             | -9.956819 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 279       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 965       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | -3.7e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 55.2      |\n",
      "|    reward             | -3.089357 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 966        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | -0.000869  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -123       |\n",
      "|    reward             | -19.609983 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 597        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 968       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | -0.000195 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -76.4     |\n",
      "|    reward             | 8.13      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 222       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 968       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | -0.000271 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 288       |\n",
      "|    reward             | -7.669923 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.15e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 970       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | -0.000996 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 5.44      |\n",
      "|    reward             | 14.936312 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 359       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 969        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.33      |\n",
      "|    explained_variance | -0.000264  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 171        |\n",
      "|    reward             | -2.6599884 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 643        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 970        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | -0.00016   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -118       |\n",
      "|    reward             | -12.398421 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.06e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 970      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.37    |\n",
      "|    explained_variance | 0.00107  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 94.4     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 267      |\n",
      "------------------------------------\n",
      "day: 583, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 192006.70\n",
      "total_reward: 92006.70\n",
      "total_cost: 0.00\n",
      "total_trades: 1541\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 972       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.37     |\n",
      "|    explained_variance | 0.00082   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 345       |\n",
      "|    reward             | 44.064793 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 3.19e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 974       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.39     |\n",
      "|    explained_variance | -0.0223   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -216      |\n",
      "|    reward             | 24.026514 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 964       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 973       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.39     |\n",
      "|    explained_variance | 8.58e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 16.5      |\n",
      "|    reward             | 4.3394575 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 93        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 970       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.39     |\n",
      "|    explained_variance | 1.19e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 367       |\n",
      "|    reward             | 11.885514 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 7e+03     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 968       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.4      |\n",
      "|    explained_variance | -0.00591  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -459      |\n",
      "|    reward             | 13.771238 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 4.64e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 965        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.38      |\n",
      "|    explained_variance | -0.00868   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -287       |\n",
      "|    reward             | -6.4784737 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.22e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 964       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.36     |\n",
      "|    explained_variance | -0.000707 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 675       |\n",
      "|    reward             | 24.621235 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.04e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 960        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.36      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -41.5      |\n",
      "|    reward             | -24.993484 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 93.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 957       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.36     |\n",
      "|    explained_variance | 0.00112   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 354       |\n",
      "|    reward             | 0.9504053 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.87e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 955        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.36      |\n",
      "|    explained_variance | -0.00147   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 159        |\n",
      "|    reward             | -3.8761365 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 561        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 954      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.35    |\n",
      "|    explained_variance | -0.00478 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -1.75    |\n",
      "|    reward             | 23.88231 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 119      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 951       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | -0.0266   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 128       |\n",
      "|    reward             | -8.450775 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 389       |\n",
      "-------------------------------------\n",
      "day: 583, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 133796.71\n",
      "total_reward: 33796.71\n",
      "total_cost: 0.00\n",
      "total_trades: 1755\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 949       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | 0.00492   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | 10.354965 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 92.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 948        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | -0.00586   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 115        |\n",
      "|    reward             | -13.902851 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 837        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 948       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -356      |\n",
      "|    reward             | 19.754997 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 5.23e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 946       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 4.79      |\n",
      "|    reward             | -2.747306 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 129       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 945       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 0.00114   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -5.45     |\n",
      "|    reward             | -4.231517 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.93      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 944        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | -0.0186    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -229       |\n",
      "|    reward             | -20.099012 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 797        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 942        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.29      |\n",
      "|    explained_variance | 0.0039     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 397        |\n",
      "|    reward             | -47.006603 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 5.12e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 942       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | -0.0154   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 92.2      |\n",
      "|    reward             | 0.3324076 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 246       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 941        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.32      |\n",
      "|    explained_variance | -0.0164    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -211       |\n",
      "|    reward             | -15.713995 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.17e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 940      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.33    |\n",
      "|    explained_variance | -0.0004  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 79.2     |\n",
      "|    reward             | 6.749108 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 191      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 939        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | 0.00102    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 67.1       |\n",
      "|    reward             | -20.784073 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 89         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 939       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | -0.0137   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -29.1     |\n",
      "|    reward             | -67.44787 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 44.4      |\n",
      "-------------------------------------\n",
      "day: 583, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 149870.23\n",
      "total_reward: 49870.23\n",
      "total_cost: 0.00\n",
      "total_trades: 1017\n",
      "Sharpe: 0.648\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 938      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.33    |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 5.52     |\n",
      "|    reward             | 16.45105 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 8.22     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 937       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | -0.0052   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 142       |\n",
      "|    reward             | 36.335075 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 532       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 937        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | 0.00354    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -12.4      |\n",
      "|    reward             | -30.380817 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 183        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 936        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | 0.00825    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -37.5      |\n",
      "|    reward             | -11.830497 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 54.8       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 936      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.29    |\n",
      "|    explained_variance | -0.00513 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 222      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 989      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 936       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.29     |\n",
      "|    explained_variance | -0.00209  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -1.37e+03 |\n",
      "|    reward             | 11.710985 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.98e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 935        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.3       |\n",
      "|    explained_variance | -0.00516   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 70.2       |\n",
      "|    reward             | -2.3540854 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 266        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 934       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | -0.000947 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -1.56     |\n",
      "|    reward             | -8.229628 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 174       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 934      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.27    |\n",
      "|    explained_variance | -0.00332 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 283      |\n",
      "|    reward             | 32.97931 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.2e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 933       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | -0.000117 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 209       |\n",
      "|    reward             | -8.160817 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 964       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 933       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | -0.000261 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -102      |\n",
      "|    reward             | 2.405     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 245       |\n",
      "-------------------------------------\n",
      "day: 583, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 113791.47\n",
      "total_reward: 13791.47\n",
      "total_cost: 0.00\n",
      "total_trades: 1124\n",
      "Sharpe: 0.338\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 932       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | 9.54e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 87.1      |\n",
      "|    reward             | 18.156567 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 166       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 932       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -456      |\n",
      "|    reward             | 71.501076 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 4.74e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 932       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 0.00018   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 0.391     |\n",
      "|    reward             | -9.567497 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 304       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 933        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.32      |\n",
      "|    explained_variance | 0.000284   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -222       |\n",
      "|    reward             | -19.773594 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.39e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 935       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.31     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -34.7     |\n",
      "|    reward             | -20.40175 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 110       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 938        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 97.7       |\n",
      "|    reward             | -3.3792922 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 300        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 940       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | -1.88e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -145      |\n",
      "|    reward             | 6.6597056 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 547       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 941       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | 8.42e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -99.5     |\n",
      "|    reward             | 12.982361 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 414       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 943       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 149       |\n",
      "|    reward             | 10.092555 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 756       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 945       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 0.1661612 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 530       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 946       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -181      |\n",
      "|    reward             | -4.652673 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 841       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 948       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 86        |\n",
      "|    reward             | 27.206635 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 165       |\n",
      "-------------------------------------\n",
      "day: 583, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 136707.71\n",
      "total_reward: 36707.71\n",
      "total_cost: 0.00\n",
      "total_trades: 1759\n",
      "Sharpe: 0.629\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 950        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.3       |\n",
      "|    explained_variance | -2.77e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 203        |\n",
      "|    reward             | -25.818613 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 709        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 952       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -286      |\n",
      "|    reward             | 5.3128943 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.15e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 954       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.36     |\n",
      "|    explained_variance | 9.42e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 138       |\n",
      "|    reward             | 7.6353292 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 435       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 955       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -23.4     |\n",
      "|    reward             | 21.125685 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 125       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 957       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | -9.78e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 242       |\n",
      "|    reward             | 13.662134 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.54e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 958       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -60.9     |\n",
      "|    reward             | 10.662688 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 957       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 42.9      |\n",
      "|    reward             | 7.0844727 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 57.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 959        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.35      |\n",
      "|    explained_variance | -9.54e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 76.1       |\n",
      "|    reward             | -24.903526 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 231        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 960        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.36      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 185        |\n",
      "|    reward             | -5.7221785 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 614        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 962       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -308      |\n",
      "|    reward             | -9.965953 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.69e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 963       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 125       |\n",
      "|    reward             | 18.785015 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 831       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 964       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.41     |\n",
      "|    explained_variance | -1.14e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -251      |\n",
      "|    reward             | -7.864194 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.29e+03  |\n",
      "-------------------------------------\n",
      "day: 583, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 133444.98\n",
      "total_reward: 33444.98\n",
      "total_cost: 0.00\n",
      "total_trades: 1831\n",
      "Sharpe: 0.515\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 967       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.43     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -9.52     |\n",
      "|    reward             | -8.659173 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 715       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 969        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.42      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 80.5       |\n",
      "|    reward             | -4.6222415 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 109        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 972       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.42     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -222      |\n",
      "|    reward             | 12.689904 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.16e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 974        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.42      |\n",
      "|    explained_variance | -3.93e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -162       |\n",
      "|    reward             | -22.193008 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 686        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 976        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.43      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 38         |\n",
      "|    reward             | -25.573769 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 162        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 978       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.39     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -117      |\n",
      "|    reward             | 7.6203804 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 680       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 980      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -23.4    |\n",
      "|    reward             | 8.71787  |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 983       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.41     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 75.1      |\n",
      "|    reward             | -3.792539 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 273       |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the A2C model with the defined total number of time steps, only if if_using_a2c is set to True.\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained A2C model to the specified directory, only if if_using_a2c is set to True.\n",
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to files/results_PORTFOLIO/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 583, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170495.35\n",
      "total_reward: 70495.35\n",
      "total_cost: 0.00\n",
      "total_trades: 1950\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1888     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "| train/             |          |\n",
      "|    reward          | 8.470789 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1548        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009977 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.000462    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -16.34935   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1389         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047095725 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | 0.00329      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00941     |\n",
      "|    reward               | -12.903356   |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 114026.53\n",
      "total_reward: 14026.53\n",
      "total_cost: 0.00\n",
      "total_trades: 1948\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1329        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005814143 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.00409     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    reward               | 5.0427823   |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 3.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064604683 |\n",
      "|    clip_fraction        | 0.0657       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.08        |\n",
      "|    explained_variance   | 0.00316      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | -0.30126512  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1290         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069762403 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.00211      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | -36.691254   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "day: 583, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 187005.89\n",
      "total_reward: 87005.89\n",
      "total_cost: 0.00\n",
      "total_trades: 1926\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1261        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009009829 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.000228    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.81e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 5.74722     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1249        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008639567 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.000722    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | -6.387549   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007431097 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.00158     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -6.78       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.42e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 85588.11\n",
      "total_reward: -14411.89\n",
      "total_cost: 0.00\n",
      "total_trades: 1951\n",
      "Sharpe: -0.039\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1236        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008862507 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.00259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 20.666067   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1235        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007245983 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.00767     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 112.037056  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1233        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003862115 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.84e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | -70.59918   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 7.24e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 118447.33\n",
      "total_reward: 18447.33\n",
      "total_cost: 0.00\n",
      "total_trades: 1923\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1233        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006416994 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.00506     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.46e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -10.024308  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1233         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064034797 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.0045       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.7e+03      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    reward               | 13.389498    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.23e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1234        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006933356 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.00949     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.87e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 13.798208   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.1e+03     |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 130097.55\n",
      "total_reward: 30097.55\n",
      "total_cost: 0.00\n",
      "total_trades: 1953\n",
      "Sharpe: 0.517\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1236         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039980365 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.025        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 984          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | 35.002193    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1237         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035010935 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    reward               | -3.9720404   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 79434.83\n",
      "total_reward: -20565.17\n",
      "total_cost: 0.00\n",
      "total_trades: 1873\n",
      "Sharpe: -0.077\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1238        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004524467 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.0378      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 25.780752   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1234         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028573154 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | 12.632329    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1236        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004762839 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2e+03     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 23.794683   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.05e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 167995.65\n",
      "total_reward: 67995.65\n",
      "total_cost: 0.00\n",
      "total_trades: 1961\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1238         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048722276 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.8e+03      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00977     |\n",
      "|    reward               | -14.395981   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1241        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004856909 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.0549      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.69e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | -12.083326  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1243         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037144138 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.64e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | 1.6920205    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.57e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 132484.55\n",
      "total_reward: 32484.55\n",
      "total_cost: 0.00\n",
      "total_trades: 1979\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1245        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005442815 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0643      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.64e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -2.2927222  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.15e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1242         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035795919 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.0942       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | 25.089474    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1243        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004366694 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.28e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | -13.724035  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.01e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 94513.49\n",
      "total_reward: -5486.51\n",
      "total_cost: 0.00\n",
      "total_trades: 1880\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1245        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324452 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0961      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.66e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 21.770489   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1241         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038634404 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.0859       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | 1.0384918    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1242         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042194463 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.0957       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.2e+03      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    reward               | 0.8114671    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.93e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 132332.60\n",
      "total_reward: 32332.60\n",
      "total_cost: 0.00\n",
      "total_trades: 1853\n",
      "Sharpe: 0.521\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1242        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005916509 |\n",
      "|    clip_fraction        | 0.0299      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | -3.6771076  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.53e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1244        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004080537 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -8.799697   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1246        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005457118 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.96e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 2.92        |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 259170.66\n",
      "total_reward: 159170.66\n",
      "total_cost: 0.00\n",
      "total_trades: 1958\n",
      "Sharpe: 1.310\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1247         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046966127 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.4e+03      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    reward               | -0.983985    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1246         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047614197 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | 0.0986       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    reward               | -4.170582    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.53e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1246        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005218289 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33e+03    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -19.164288  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.36e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 125196.77\n",
      "total_reward: 25196.77\n",
      "total_cost: 0.00\n",
      "total_trades: 1844\n",
      "Sharpe: 0.449\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1246        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004394791 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 26.03053    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1245         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034857076 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | -24.673517   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.48e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 277960.31\n",
      "total_reward: 177960.31\n",
      "total_cost: 0.00\n",
      "total_trades: 1971\n",
      "Sharpe: 1.439\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1246        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005211385 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | 12.672927   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.07e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1244         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027713294 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.15        |\n",
      "|    explained_variance   | 0.0952       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.04e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | -10.388692   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1243         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062443824 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.15        |\n",
      "|    explained_variance   | 0.0887       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    reward               | 26.401222    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.29e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 227277.08\n",
      "total_reward: 127277.08\n",
      "total_cost: 0.00\n",
      "total_trades: 1853\n",
      "Sharpe: 1.076\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905981 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.15       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.27e+03    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 27.805159   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1239        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008030616 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.16       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.72e+03    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -10.54679   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.29e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1237         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065767514 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.16        |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.98e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | 5.28997      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.9e+03      |\n",
      "------------------------------------------\n",
      "day: 583, episode: 240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170696.64\n",
      "total_reward: 70696.64\n",
      "total_cost: 0.00\n",
      "total_trades: 1896\n",
      "Sharpe: 0.778\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1238         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073138736 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.17        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.56e+03     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | 29.12267     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1239         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064873667 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.18        |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29e+03     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | -27.131834   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 7.23e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008010032 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.18       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | 0.13199463  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.2e+03     |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 150056.73\n",
      "total_reward: 50056.73\n",
      "total_cost: 0.00\n",
      "total_trades: 1842\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1241        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006181079 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.18       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.74e+03    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -10.719206  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1239        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109894 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.19       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.28e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 16.748926   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.34e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1240         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061467057 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.19        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | 45.104507    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.67e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 145915.26\n",
      "total_reward: 45915.26\n",
      "total_cost: 0.00\n",
      "total_trades: 1872\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1241         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046041384 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.18        |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.47e+03     |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -15.089773   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 6.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1242         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051091155 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.18        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.66e+03     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | 8.488073     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1241        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005066856 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.19       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -5.4484863  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 257476.52\n",
      "total_reward: 157476.52\n",
      "total_cost: 0.00\n",
      "total_trades: 1872\n",
      "Sharpe: 1.318\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1240         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045680953 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.19        |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.56e+03     |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    reward               | -20.529095   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 6.08e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004510469 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.19       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.31e+03    |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -30.3992    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006464932 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.2        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 31.001732   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.51e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 130650.36\n",
      "total_reward: 30650.36\n",
      "total_cost: 0.00\n",
      "total_trades: 1820\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1239        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004004385 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.21       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | -12.195878  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1238        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006276855 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.21       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.55e+03    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 3.4420938   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.9e+03     |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 219658.51\n",
      "total_reward: 119658.51\n",
      "total_cost: 0.00\n",
      "total_trades: 1900\n",
      "Sharpe: 1.099\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1237         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040649655 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.21        |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.89e+03     |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -0.74570584  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1236         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027100067 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.21        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.04e+03     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -12.123983   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 9.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1235         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061742817 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.21        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.12e+03     |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 18.599691    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 6.59e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109354.96\n",
      "total_reward: 9354.96\n",
      "total_cost: 0.00\n",
      "total_trades: 1870\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1235        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006406716 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.2        |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.61e+03    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1235         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049759867 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.2         |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | 0.8292387    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1237        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007036198 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.2        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | 0.507576    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 241719.13\n",
      "total_reward: 141719.13\n",
      "total_cost: 0.00\n",
      "total_trades: 1917\n",
      "Sharpe: 1.230\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1237         |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037496788 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.2         |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.9e+03      |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 32.483994    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1238         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037422087 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.21        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29e+03     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | 7.672169     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1237        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005574177 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.22       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.79e+03    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -1.7576848  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.65e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 306571.71\n",
      "total_reward: 206571.71\n",
      "total_cost: 0.00\n",
      "total_trades: 1933\n",
      "Sharpe: 1.496\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1235         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029420978 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.22        |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -1.7541498   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1236         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052421642 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.22        |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.59e+03     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | 13.48378     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 6.2e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006139262 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.27e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -33.566162  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.2e+03     |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 117688.12\n",
      "total_reward: 17688.12\n",
      "total_cost: 0.00\n",
      "total_trades: 1886\n",
      "Sharpe: 0.377\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1242        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004445993 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.67e+03    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -15.452354  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.18e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1247         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034298017 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | -60.28576    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1250         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022963393 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | 7.761643     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.97e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122922.35\n",
      "total_reward: 22922.35\n",
      "total_cost: 0.00\n",
      "total_trades: 1851\n",
      "Sharpe: 0.431\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1253         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037244183 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | -5.056581    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 7.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1257         |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036057592 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.24        |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.37e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 32.66281     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.65e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 245080.07\n",
      "total_reward: 145080.07\n",
      "total_cost: 0.00\n",
      "total_trades: 1907\n",
      "Sharpe: 1.163\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1258         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076028486 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.24        |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | -24.04045    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1261       |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00544312 |\n",
      "|    clip_fraction        | 0.0295     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.24      |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.48e+03   |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00756   |\n",
      "|    reward               | -50.5606   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 5.29e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005713011 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.85e+03    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -13.290616  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.38e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 173935.53\n",
      "total_reward: 73935.53\n",
      "total_cost: 0.00\n",
      "total_trades: 1820\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1266         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042749513 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.26        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.28e+03     |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | -11.950928   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 7.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1270         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055118864 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.26        |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    reward               | -53.13       |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 3.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1273         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022938922 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.27        |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.75e+03     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 11.980217    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.06e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 237792.13\n",
      "total_reward: 137792.13\n",
      "total_cost: 0.00\n",
      "total_trades: 1783\n",
      "Sharpe: 1.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1277       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 129        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00499822 |\n",
      "|    clip_fraction        | 0.0293     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.27      |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.13e+03   |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.00452   |\n",
      "|    reward               | -6.6394916 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 5.34e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1277        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004675394 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.28       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.29e+03    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -7.435407   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 7.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1275         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032315324 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.28        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.67e+03     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 8.072973     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.65e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 380\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 157875.06\n",
      "total_reward: 57875.06\n",
      "total_cost: 0.00\n",
      "total_trades: 1819\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1278         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054507367 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.28        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.56e+03     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 12.889124    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 6.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1280        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005050742 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.28       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22e+03    |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | -21.524036  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1277         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026742718 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.28        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.6e+03      |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -1.8767798   |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.24e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 253109.15\n",
      "total_reward: 153109.15\n",
      "total_cost: 0.00\n",
      "total_trades: 1792\n",
      "Sharpe: 1.223\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1279         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050008153 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.28        |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.88e+03     |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | 24.8625      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1278         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024031438 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.29        |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 18.67184     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.29e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1279        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001597321 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.29       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 35.947594   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 3.3e+03     |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 400\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 262321.53\n",
      "total_reward: 162321.53\n",
      "total_cost: 0.00\n",
      "total_trades: 1806\n",
      "Sharpe: 1.257\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1280         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035712137 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.3         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.94e+03     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 6.4106097    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 5.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004393547 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.3        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 41.792397   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 5.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1281        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005180018 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.31       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -0.4154831  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 5.23e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 410\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 252243.51\n",
      "total_reward: 152243.51\n",
      "total_cost: 0.00\n",
      "total_trades: 1795\n",
      "Sharpe: 1.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006461519 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.31       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 29.638039   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.96e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1283         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019813979 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.31        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.55e+03     |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | -6.6239867   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 6.85e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 420\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 106414.00\n",
      "total_reward: 6414.00\n",
      "total_cost: 0.00\n",
      "total_trades: 1863\n",
      "Sharpe: 0.280\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1283         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028834427 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.32        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.5e+03      |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 10.861873    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 4.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002919953 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.32       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.92e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -11.732377  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 7.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004908899 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.34       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -3.7572362  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 430\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 147770.22\n",
      "total_reward: 47770.22\n",
      "total_cost: 0.00\n",
      "total_trades: 1789\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1284         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044586738 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.35        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 14.818766    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 4.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1285         |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045349207 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.35        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 1.2535863    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 5.22e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1285         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027294355 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.35        |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 18.747292    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 3.35e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 440\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 257895.03\n",
      "total_reward: 157895.03\n",
      "total_cost: 0.00\n",
      "total_trades: 1843\n",
      "Sharpe: 1.282\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1286         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027126544 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.35        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.67e+03     |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -32.634903   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 4.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1287         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041177925 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.36        |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.18e+03     |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 8.906298     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 6.25e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1288         |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051257657 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.37        |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 4.110783     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 6.03e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 450\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 154605.63\n",
      "total_reward: 54605.63\n",
      "total_cost: 0.00\n",
      "total_trades: 1908\n",
      "Sharpe: 0.657\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1288         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042892443 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.37        |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.47e+03     |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | -4.5784664   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 5.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1288         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039133304 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.38        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -11.734404   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 5.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1289        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005271407 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.38       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.29e+03    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -0.25488922 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 5.48e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 460\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 241878.96\n",
      "total_reward: 141878.96\n",
      "total_cost: 0.00\n",
      "total_trades: 1825\n",
      "Sharpe: 1.145\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046257977 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | -6.915599    |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 3.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028434186 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.09e+03     |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | 7.884013     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 7.52e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1293       |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 172        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00240692 |\n",
      "|    clip_fraction        | 0.0175     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.39      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.26e+03   |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    reward               | 26.61083   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 4.51e+03   |\n",
      "----------------------------------------\n",
      "day: 583, episode: 470\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 312637.48\n",
      "total_reward: 212637.48\n",
      "total_cost: 0.00\n",
      "total_trades: 1894\n",
      "Sharpe: 1.527\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1292       |\n",
      "|    iterations           | 110        |\n",
      "|    time_elapsed         | 174        |\n",
      "|    total_timesteps      | 225280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00342632 |\n",
      "|    clip_fraction        | 0.018      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.39      |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.06e+03   |\n",
      "|    n_updates            | 1090       |\n",
      "|    policy_gradient_loss | -0.00473   |\n",
      "|    reward               | -29.08889  |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 6.61e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034094865 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.4         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -4.4117384   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 5.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004776698 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.1e+03     |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -27.761726  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 4.17e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 480\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 169278.03\n",
      "total_reward: 69278.03\n",
      "total_cost: 0.00\n",
      "total_trades: 1853\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057788743 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.4         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 7.5428576    |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 4.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028202746 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.4         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 27.50936     |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 3.64e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 490\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159654.65\n",
      "total_reward: 59654.65\n",
      "total_cost: 0.00\n",
      "total_trades: 1911\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005091386 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | -17.375984  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041591856 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.41        |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.31e+03     |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -13.177548   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005526096 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 18.24       |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 500\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122966.96\n",
      "total_reward: 22966.96\n",
      "total_cost: 0.00\n",
      "total_trades: 1845\n",
      "Sharpe: 0.428\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002244909 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.97e+03    |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -15.115318  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 6.17e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049080504 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.42        |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.95e+03     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | -5.6115108   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 4.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019326967 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.43        |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.49e+03     |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -8.361204    |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 6.89e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 510\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 114316.09\n",
      "total_reward: 14316.09\n",
      "total_cost: 0.00\n",
      "total_trades: 1821\n",
      "Sharpe: 0.354\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050295554 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.43        |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.35e+03     |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | 1.0402151    |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 3.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049642315 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.44        |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.04e+03     |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | 38.42332     |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 4.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038567418 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.44        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | -12.534878   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 520\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170828.63\n",
      "total_reward: 70828.63\n",
      "total_cost: 0.00\n",
      "total_trades: 1845\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1299       |\n",
      "|    iterations           | 124        |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 253952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00480039 |\n",
      "|    clip_fraction        | 0.0347     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.45      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 873        |\n",
      "|    n_updates            | 1230       |\n",
      "|    policy_gradient_loss | -0.00464   |\n",
      "|    reward               | 12.342169  |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 2.66e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031932169 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.45        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -20.811579   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003777991 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.45       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.86e+03    |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -33.52416   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 5.44e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 185448.10\n",
      "total_reward: 85448.10\n",
      "total_cost: 0.00\n",
      "total_trades: 1853\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042482466 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.45        |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | -65.98506    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025655502 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.46        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 42.17141     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020064726 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.46        |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.73e+03     |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -15.080073   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 4.67e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 540\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 172668.78\n",
      "total_reward: 72668.78\n",
      "total_cost: 0.00\n",
      "total_trades: 1885\n",
      "Sharpe: 0.766\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022865138 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.47        |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | -20.025364   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1300         |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067157955 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.47        |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | -11.70722    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048481105 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.48        |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 913          |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | 36.437756    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 2.46e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 550\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 181677.08\n",
      "total_reward: 81677.08\n",
      "total_cost: 0.00\n",
      "total_trades: 1793\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033338314 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.49        |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 959          |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 16.393993    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046345545 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.48        |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 836          |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | 43.517563    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 2.39e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 560\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 326868.24\n",
      "total_reward: 226868.24\n",
      "total_cost: 0.00\n",
      "total_trades: 1855\n",
      "Sharpe: 1.473\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031000115 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.48        |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.78e+03     |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 0.5589267    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 4.17e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003435331 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.48       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.41e+03    |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 2.9523046   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 5.51e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1300         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029848826 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.49        |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 20.69546     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 3.83e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 570\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 161704.72\n",
      "total_reward: 61704.72\n",
      "total_cost: 0.00\n",
      "total_trades: 1927\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004378818 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.49       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | -24.985268  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 3.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045826123 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.49        |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 7.334059     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029522902 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.49        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.47e+03     |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | -5.2807503   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 4.26e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 580\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 140966.06\n",
      "total_reward: 40966.06\n",
      "total_cost: 0.00\n",
      "total_trades: 1903\n",
      "Sharpe: 0.565\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022747377 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.49        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -31.966452   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 4.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030414471 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.5         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | 9.0836       |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025038172 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.16e+03     |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | -11.964643   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 5.56e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 590\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 99313.15\n",
      "total_reward: -686.85\n",
      "total_cost: 0.00\n",
      "total_trades: 1870\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032460769 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 13.196728    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048534684 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    reward               | 9.487174     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00268996 |\n",
      "|    clip_fraction        | 0.0149     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.51      |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.81e+03   |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.00499   |\n",
      "|    reward               | -7.459204  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 3.97e+03   |\n",
      "----------------------------------------\n",
      "day: 583, episode: 600\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 142942.14\n",
      "total_reward: 42942.14\n",
      "total_cost: 0.00\n",
      "total_trades: 1838\n",
      "Sharpe: 0.576\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 229          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046214405 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    reward               | 19.122574    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056201043 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -31.533674   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 232          |\n",
      "|    total_timesteps      | 305152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037485752 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.52        |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -39.208702   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 4.71e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 610\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 160272.58\n",
      "total_reward: 60272.58\n",
      "total_cost: 0.00\n",
      "total_trades: 1896\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 233          |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034194137 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.53        |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 1490         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    reward               | -6.507443    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056171645 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.53        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -8.20415     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.47e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 620\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 184266.65\n",
      "total_reward: 84266.65\n",
      "total_cost: 0.00\n",
      "total_trades: 1837\n",
      "Sharpe: 0.821\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1318         |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036357702 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.53        |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -35.738438   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 313344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034022294 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 5.8555293    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 3.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 315392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030554864 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -8.403489    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.14e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 630\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 148792.08\n",
      "total_reward: 48792.08\n",
      "total_cost: 0.00\n",
      "total_trades: 1878\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 240          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023857523 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 6.4309783    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042575896 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 11.122764    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.19e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1323         |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 321536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027481103 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.55        |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | 13.361124    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 640\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 175097.01\n",
      "total_reward: 75097.01\n",
      "total_cost: 0.00\n",
      "total_trades: 1781\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1323         |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 244          |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043369457 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.55        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | -46.465786   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1325         |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028170622 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -20.763605   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1326         |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021564197 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 26.0325      |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 650\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159555.85\n",
      "total_reward: 59555.85\n",
      "total_cost: 0.00\n",
      "total_trades: 1858\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1327         |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023652667 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 17.455626    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1329         |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 249          |\n",
      "|    total_timesteps      | 331776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028771735 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | 24.975994    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 333824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037999072 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | 7.5433116    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 660\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159279.34\n",
      "total_reward: 59279.34\n",
      "total_cost: 0.00\n",
      "total_trades: 1892\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1331        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004208913 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.56       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 19.683615   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037584985 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79e+03     |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 9.743945     |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 4.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1335         |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 254          |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041113878 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.56        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 28.582436    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 670\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 225225.94\n",
      "total_reward: 125225.94\n",
      "total_cost: 0.00\n",
      "total_trades: 1833\n",
      "Sharpe: 1.070\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1336         |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 342016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020971769 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.57        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -5.8811855   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1338       |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00534101 |\n",
      "|    clip_fraction        | 0.0328     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.57      |\n",
      "|    explained_variance   | 0.763      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.43e+03   |\n",
      "|    n_updates            | 1670       |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    reward               | 15.257462  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.6e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027755778 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.57        |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -28.829643   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 680\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 322153.59\n",
      "total_reward: 222153.59\n",
      "total_cost: 0.00\n",
      "total_trades: 1844\n",
      "Sharpe: 1.465\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1341         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028706007 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.57        |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 897          |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -3.3347318   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1342         |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 350208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044486183 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.58        |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.9e+03      |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | 18.824158    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 3.53e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 690\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 213008.15\n",
      "total_reward: 113008.15\n",
      "total_cost: 0.00\n",
      "total_trades: 1845\n",
      "Sharpe: 1.012\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1344        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004421524 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.58       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    reward               | 0.23558624  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002543326 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.58       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 25.811188   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1347         |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025627231 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.58        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.94e+03     |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | 1.7576861    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 4.87e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 700\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 147745.54\n",
      "total_reward: 47745.54\n",
      "total_cost: 0.00\n",
      "total_trades: 1872\n",
      "Sharpe: 0.616\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002768046 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.59       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 15.919995   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1350         |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022525743 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.59        |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | -0.73222303  |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021895901 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.59        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -2.4196353   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 710\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 167286.91\n",
      "total_reward: 67286.91\n",
      "total_cost: 0.00\n",
      "total_trades: 1868\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1352        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002209867 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.6        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | -24.502407  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1354         |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028352593 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.6         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    reward               | -0.25738952  |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1355         |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028199188 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.6         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -8.542798    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 4.41e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 720\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170603.56\n",
      "total_reward: 70603.56\n",
      "total_cost: 0.00\n",
      "total_trades: 1854\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002512224 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.61       |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 977         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 8.0640135   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1357         |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036944563 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.61        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 27.688526    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018085805 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.61        |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -40.03919    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 730\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 148724.42\n",
      "total_reward: 48724.42\n",
      "total_cost: 0.00\n",
      "total_trades: 1866\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1360        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003193398 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.61       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -1.211963   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1361         |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034052972 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.61        |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -44.03694    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1363         |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 380928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027144449 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.61        |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 7.0788603    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 740\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 178812.44\n",
      "total_reward: 78812.44\n",
      "total_cost: 0.00\n",
      "total_trades: 1868\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028411793 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -0.72778624  |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.18e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1365         |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042772843 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 1870         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 61.797787    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001663344 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.62       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -19.846872  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 750\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 210655.63\n",
      "total_reward: 110655.63\n",
      "total_cost: 0.00\n",
      "total_trades: 1836\n",
      "Sharpe: 1.000\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002153817 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.62       |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | 31.84       |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.45e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 285          |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025474746 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -30.530535   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.25e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 760\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 192381.46\n",
      "total_reward: 92381.46\n",
      "total_cost: 0.00\n",
      "total_trades: 1845\n",
      "Sharpe: 0.880\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1370         |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028187619 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -5.5581107   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003252557 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.62       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | -10.085806  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017723381 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.62        |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 12.795421    |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "day: 583, episode: 770\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 135791.05\n",
      "total_reward: 35791.05\n",
      "total_cost: 0.00\n",
      "total_trades: 1789\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 290          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034543485 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.63        |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | 49.6611      |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021797996 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.63        |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | -10.240982   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=400000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to files/results_PORTFOLIO/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 196      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2336     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.082    |\n",
      "|    critic_loss     | 370      |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | 27.6     |\n",
      "|    learning_rate   | 0.0001   |\n",
      "|    n_updates       | 2235     |\n",
      "|    reward          | 8.161451 |\n",
      "---------------------------------\n",
      "day: 583, episode: 780\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 152622.67\n",
      "total_reward: 52622.67\n",
      "total_cost: 0.00\n",
      "total_trades: 1395\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 182        |\n",
      "|    time_elapsed    | 25         |\n",
      "|    total_timesteps | 4672       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 43.9       |\n",
      "|    critic_loss     | 528        |\n",
      "|    ent_coef        | 0.152      |\n",
      "|    ent_coef_loss   | 22.7       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 4571       |\n",
      "|    reward          | -6.8597918 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 181        |\n",
      "|    time_elapsed    | 38         |\n",
      "|    total_timesteps | 7008       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 71.6       |\n",
      "|    critic_loss     | 824        |\n",
      "|    ent_coef        | 0.191      |\n",
      "|    ent_coef_loss   | 14.5       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6907       |\n",
      "|    reward          | -14.430283 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 790\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122281.32\n",
      "total_reward: 22281.32\n",
      "total_cost: 0.00\n",
      "total_trades: 1931\n",
      "Sharpe: 0.417\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 181         |\n",
      "|    time_elapsed    | 51          |\n",
      "|    total_timesteps | 9344        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 103         |\n",
      "|    critic_loss     | 416         |\n",
      "|    ent_coef        | 0.238       |\n",
      "|    ent_coef_loss   | 11.5        |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 9243        |\n",
      "|    reward          | -13.5650835 |\n",
      "------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 182        |\n",
      "|    time_elapsed    | 63         |\n",
      "|    total_timesteps | 11680      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 122        |\n",
      "|    critic_loss     | 660        |\n",
      "|    ent_coef        | 0.286      |\n",
      "|    ent_coef_loss   | 3.11       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 11579      |\n",
      "|    reward          | -14.708383 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 181        |\n",
      "|    time_elapsed    | 77         |\n",
      "|    total_timesteps | 14016      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 133        |\n",
      "|    critic_loss     | 311        |\n",
      "|    ent_coef        | 0.332      |\n",
      "|    ent_coef_loss   | 3.1        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 13915      |\n",
      "|    reward          | -13.132484 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 800\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 111706.68\n",
      "total_reward: 11706.68\n",
      "total_cost: 0.00\n",
      "total_trades: 2109\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 170        |\n",
      "|    time_elapsed    | 95         |\n",
      "|    total_timesteps | 16352      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 158        |\n",
      "|    critic_loss     | 527        |\n",
      "|    ent_coef        | 0.397      |\n",
      "|    ent_coef_loss   | 3.17       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 16251      |\n",
      "|    reward          | -15.163082 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 159        |\n",
      "|    time_elapsed    | 117        |\n",
      "|    total_timesteps | 18688      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 171        |\n",
      "|    critic_loss     | 181        |\n",
      "|    ent_coef        | 0.485      |\n",
      "|    ent_coef_loss   | 0.851      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 18587      |\n",
      "|    reward          | -14.275784 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 810\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 123364.27\n",
      "total_reward: 23364.27\n",
      "total_cost: 0.00\n",
      "total_trades: 2110\n",
      "Sharpe: 0.427\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 138        |\n",
      "|    time_elapsed    | 151        |\n",
      "|    total_timesteps | 21024      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 180        |\n",
      "|    critic_loss     | 1.07e+03   |\n",
      "|    ent_coef        | 0.577      |\n",
      "|    ent_coef_loss   | 1.43       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 20923      |\n",
      "|    reward          | -0.6810054 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 135        |\n",
      "|    time_elapsed    | 172        |\n",
      "|    total_timesteps | 23360      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 208        |\n",
      "|    critic_loss     | 499        |\n",
      "|    ent_coef        | 0.716      |\n",
      "|    ent_coef_loss   | 0.823      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 23259      |\n",
      "|    reward          | -15.110082 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 137        |\n",
      "|    time_elapsed    | 186        |\n",
      "|    total_timesteps | 25696      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 235        |\n",
      "|    critic_loss     | 438        |\n",
      "|    ent_coef        | 0.859      |\n",
      "|    ent_coef_loss   | 0.0428     |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 25595      |\n",
      "|    reward          | -14.831983 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 820\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 126316.82\n",
      "total_reward: 26316.82\n",
      "total_cost: 0.00\n",
      "total_trades: 2251\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 141        |\n",
      "|    time_elapsed    | 197        |\n",
      "|    total_timesteps | 28032      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 242        |\n",
      "|    critic_loss     | 561        |\n",
      "|    ent_coef        | 0.996      |\n",
      "|    ent_coef_loss   | -3.01e-05  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 27931      |\n",
      "|    reward          | -14.183084 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 145        |\n",
      "|    time_elapsed    | 209        |\n",
      "|    total_timesteps | 30368      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 295        |\n",
      "|    critic_loss     | 601        |\n",
      "|    ent_coef        | 1.12       |\n",
      "|    ent_coef_loss   | -0.142     |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 30267      |\n",
      "|    reward          | -14.924683 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 830\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 92878.09\n",
      "total_reward: -7121.91\n",
      "total_cost: 0.00\n",
      "total_trades: 2116\n",
      "Sharpe: 0.117\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 148        |\n",
      "|    time_elapsed    | 220        |\n",
      "|    total_timesteps | 32704      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 333        |\n",
      "|    critic_loss     | 470        |\n",
      "|    ent_coef        | 1.21       |\n",
      "|    ent_coef_loss   | -0.0123    |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 32603      |\n",
      "|    reward          | -14.831983 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 150        |\n",
      "|    time_elapsed    | 232        |\n",
      "|    total_timesteps | 35040      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 301        |\n",
      "|    critic_loss     | 221        |\n",
      "|    ent_coef        | 0.982      |\n",
      "|    ent_coef_loss   | -0.0804    |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 34939      |\n",
      "|    reward          | -15.110082 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 64         |\n",
      "|    fps             | 153        |\n",
      "|    time_elapsed    | 243        |\n",
      "|    total_timesteps | 37376      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 257        |\n",
      "|    critic_loss     | 256        |\n",
      "|    ent_coef        | 0.774      |\n",
      "|    ent_coef_loss   | -1.1       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 37275      |\n",
      "|    reward          | -20.981075 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 840\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 126180.68\n",
      "total_reward: 26180.68\n",
      "total_cost: 0.00\n",
      "total_trades: 2115\n",
      "Sharpe: 0.452\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 68         |\n",
      "|    fps             | 155        |\n",
      "|    time_elapsed    | 255        |\n",
      "|    total_timesteps | 39712      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 231        |\n",
      "|    critic_loss     | 346        |\n",
      "|    ent_coef        | 0.614      |\n",
      "|    ent_coef_loss   | -1.77      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 39611      |\n",
      "|    reward          | -14.770183 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 155        |\n",
      "|    time_elapsed    | 270        |\n",
      "|    total_timesteps | 42048      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 206        |\n",
      "|    critic_loss     | 353        |\n",
      "|    ent_coef        | 0.487      |\n",
      "|    ent_coef_loss   | -2.7       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 41947      |\n",
      "|    reward          | -10.907687 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 850\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 123921.32\n",
      "total_reward: 23921.32\n",
      "total_cost: 0.00\n",
      "total_trades: 1774\n",
      "Sharpe: 0.432\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 76         |\n",
      "|    fps             | 154        |\n",
      "|    time_elapsed    | 287        |\n",
      "|    total_timesteps | 44384      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 174        |\n",
      "|    critic_loss     | 151        |\n",
      "|    ent_coef        | 0.388      |\n",
      "|    ent_coef_loss   | -4.3       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 44283      |\n",
      "|    reward          | -14.955583 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 80         |\n",
      "|    fps             | 153        |\n",
      "|    time_elapsed    | 303        |\n",
      "|    total_timesteps | 46720      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 154        |\n",
      "|    critic_loss     | 265        |\n",
      "|    ent_coef        | 0.31       |\n",
      "|    ent_coef_loss   | -3.53      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 46619      |\n",
      "|    reward          | -14.708383 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 84         |\n",
      "|    fps             | 151        |\n",
      "|    time_elapsed    | 322        |\n",
      "|    total_timesteps | 49056      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 140        |\n",
      "|    critic_loss     | 72.7       |\n",
      "|    ent_coef        | 0.248      |\n",
      "|    ent_coef_loss   | -5.2       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 48955      |\n",
      "|    reward          | -15.511782 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 860\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 125472.62\n",
      "total_reward: 25472.62\n",
      "total_cost: 0.00\n",
      "total_trades: 1774\n",
      "Sharpe: 0.446\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 88         |\n",
      "|    fps             | 147        |\n",
      "|    time_elapsed    | 347        |\n",
      "|    total_timesteps | 51392      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 129        |\n",
      "|    critic_loss     | 68.9       |\n",
      "|    ent_coef        | 0.198      |\n",
      "|    ent_coef_loss   | -5.87      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 51291      |\n",
      "|    reward          | -14.924683 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 92         |\n",
      "|    fps             | 148        |\n",
      "|    time_elapsed    | 361        |\n",
      "|    total_timesteps | 53728      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 107        |\n",
      "|    critic_loss     | 80.9       |\n",
      "|    ent_coef        | 0.159      |\n",
      "|    ent_coef_loss   | -6.89      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 53627      |\n",
      "|    reward          | -14.955583 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 870\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 123060.30\n",
      "total_reward: 23060.30\n",
      "total_cost: 0.00\n",
      "total_trades: 1532\n",
      "Sharpe: 0.424\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 96         |\n",
      "|    fps             | 150        |\n",
      "|    time_elapsed    | 373        |\n",
      "|    total_timesteps | 56064      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 74.1       |\n",
      "|    critic_loss     | 443        |\n",
      "|    ent_coef        | 0.128      |\n",
      "|    ent_coef_loss   | -3.01      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 55963      |\n",
      "|    reward          | -14.275784 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 100        |\n",
      "|    fps             | 151        |\n",
      "|    time_elapsed    | 386        |\n",
      "|    total_timesteps | 58400      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 57.1       |\n",
      "|    critic_loss     | 63         |\n",
      "|    ent_coef        | 0.105      |\n",
      "|    ent_coef_loss   | -3.61      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 58299      |\n",
      "|    reward          | -14.646583 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 104        |\n",
      "|    fps             | 152        |\n",
      "|    time_elapsed    | 398        |\n",
      "|    total_timesteps | 60736      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 78.2       |\n",
      "|    critic_loss     | 75         |\n",
      "|    ent_coef        | 0.0864     |\n",
      "|    ent_coef_loss   | -2.51      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 60635      |\n",
      "|    reward          | -14.244884 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 880\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 120985.05\n",
      "total_reward: 20985.05\n",
      "total_cost: 0.00\n",
      "total_trades: 1739\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 108        |\n",
      "|    fps             | 153        |\n",
      "|    time_elapsed    | 411        |\n",
      "|    total_timesteps | 63072      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 51.4       |\n",
      "|    critic_loss     | 246        |\n",
      "|    ent_coef        | 0.0733     |\n",
      "|    ent_coef_loss   | -0.117     |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 62971      |\n",
      "|    reward          | -14.430283 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 112        |\n",
      "|    fps             | 154        |\n",
      "|    time_elapsed    | 423        |\n",
      "|    total_timesteps | 65408      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 50.6       |\n",
      "|    critic_loss     | 156        |\n",
      "|    ent_coef        | 0.0655     |\n",
      "|    ent_coef_loss   | -0.049     |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 65307      |\n",
      "|    reward          | -14.708383 |\n",
      "-----------------------------------\n",
      "day: 583, episode: 890\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 119949.49\n",
      "total_reward: 19949.49\n",
      "total_cost: 0.00\n",
      "total_trades: 1908\n",
      "Sharpe: 0.396\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 116        |\n",
      "|    fps             | 155        |\n",
      "|    time_elapsed    | 435        |\n",
      "|    total_timesteps | 67744      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 28.6       |\n",
      "|    critic_loss     | 135        |\n",
      "|    ent_coef        | 0.0636     |\n",
      "|    ent_coef_loss   | -0.421     |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 67643      |\n",
      "|    reward          | -14.275784 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparation for backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the saved data if we have restarted the process (not required)\n",
    "train = pd.read_csv('train_data.csv')\n",
    "trade = pd.read_csv('trade_data.csv')\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the saved training data if we have restarted the process (not required)\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = True\n",
    "\n",
    "trained_a2c = A2C.load(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading (data outside the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 5, State Space: 51\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the trading environment with the defined DataFrame 'trade', turbulence threshold, and risk indicator 'vix',\n",
    "# along with other environment parameters ('env_kwargs').\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "\n",
    "# Fetching the environment compatible with Stable Baselines and the initial observations.\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# Using the DRL agent for prediction using the trained model 'trained_a2c' and the defined trading environment 'e_trade_gym'.\n",
    "# The results are two DataFrames: 'df_account_value_a2c' with account values and 'df_actions_a2c' with actions taken,\n",
    "# if 'if_using_a2c' is set to True; otherwise, it returns (None, None).\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare the DataFrame for calculating weights for mean variance optimization (MVO)\n",
    "def process_df_for_mvo(df):\n",
    "  # Sorts the DataFrame by date and stock ticker, then selects only relevant columns\n",
    "  df = df.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\n",
    "  # Takes a subset of data for the first dimension of stocks\n",
    "  fst = df.iloc[0:stock_dimension, :]\n",
    "  # Extracts the list of stock tickers\n",
    "  tic = fst['tic'].tolist()\n",
    "\n",
    "  # Initializes an empty DataFrame for MVO\n",
    "  mvo = pd.DataFrame()\n",
    "\n",
    "  # Sets initial weight values to 0 for each stock\n",
    "  for k in range(len(tic)):\n",
    "    mvo[tic[k]] = 0\n",
    "\n",
    "  # Fills the 'mvo' DataFrame with closing prices for each stock by dates\n",
    "  for i in range(df.shape[0]//stock_dimension):\n",
    "    n = df.iloc[i * stock_dimension:(i+1) * stock_dimension, :]\n",
    "    date = n['date'][i*stock_dimension]\n",
    "    mvo.loc[date] = n['close'].tolist()\n",
    "  \n",
    "  return mvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate stock returns based on their prices\n",
    "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "  import numpy as np \n",
    "  # Initializes the return matrix.\n",
    "  StockReturn = np.zeros([Rows-1, Columns]) \n",
    "  # Calculates daily return for each stock\n",
    "  for j in range(Columns):        # j: Assets \n",
    "    for i in range(Rows-1):       # i: Daily Prices \n",
    "      StockReturn[i,j] = ((StockPrice[i+1, j] - StockPrice[i,j]) / StockPrice[i,j]) * 100 \n",
    "      \n",
    "  return StockReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 224.36999512,  189.28999329,  259.8999939 ,  420.79000854,\n",
       "         629.25      ],\n",
       "       [ 219.1499939 ,  166.75      ,  247.78999329,  412.48999023,\n",
       "         620.97998047],\n",
       "       [ 199.08999634,  154.21000671,  232.32000732,  389.17001343,\n",
       "         587.03997803],\n",
       "       [ 205.30000305,  161.71000671,  241.08999634,  400.        ,\n",
       "         600.61999512],\n",
       "       [ 206.8999939 ,  166.55000305,  242.61000061,  408.64001465,\n",
       "         616.07000732],\n",
       "       [ 213.11000061,  165.16999817,  243.24000549,  402.44000244,\n",
       "         621.98999023],\n",
       "       [ 212.1000061 ,  166.3999939 ,  248.69999695,  404.02999878,\n",
       "         622.98999023],\n",
       "       [ 216.07000732,  168.13999939,  252.6000061 ,  407.05999756,\n",
       "         631.        ],\n",
       "       [ 219.00999451,  167.80999756,  253.        ,  409.58999634,\n",
       "         638.55999756],\n",
       "       [ 220.57000732,  172.11000061,  255.38999939,  414.79998779,\n",
       "         648.70001221],\n",
       "       [ 224.6000061 ,  174.86000061,  257.8999939 ,  419.79998779,\n",
       "         668.48999023],\n",
       "       [ 223.91999817,  177.03999329,  261.75      ,  420.6000061 ,\n",
       "         669.42999268],\n",
       "       [ 225.72000122,  177.63999939,  263.1000061 ,  418.95999146,\n",
       "         674.07000732],\n",
       "       [ 225.77000427,  177.91999817,  264.95001221,  421.70001221,\n",
       "         688.85998535],\n",
       "       [ 226.52000427,  179.91999817,  261.1000061 ,  424.07998657,\n",
       "         697.        ],\n",
       "       [ 227.78999329,  181.38000488,  261.5       ,  424.35998535,\n",
       "         691.        ],\n",
       "       [ 225.66000366,  177.33999634,  261.98999023,  416.98001099,\n",
       "         694.13000488],\n",
       "       [ 226.75999451,  176.69999695,  263.94000244,  416.36999512,\n",
       "         687.26000977],\n",
       "       [ 226.        ,  174.1499939 ,  259.6499939 ,  412.85998535,\n",
       "         688.5300293 ],\n",
       "       [ 227.91999817,  173.69000244,  261.82998657,  414.88000488,\n",
       "         695.83001709],\n",
       "       [ 230.1000061 ,  173.22000122,  271.01000977,  414.94000244,\n",
       "         690.        ],\n",
       "       [ 230.19000244,  172.77999878,  257.44000244,  415.6000061 ,\n",
       "         700.35998535],\n",
       "       [ 228.55000305,  177.55000305,  252.61999512,  417.91000366,\n",
       "         700.09997559],\n",
       "       [ 221.66000366,  174.47999573,  246.47000122,  405.91000366,\n",
       "         673.30999756],\n",
       "       [ 221.63000488,  175.        ,  245.97999573,  407.61999512,\n",
       "         673.14001465],\n",
       "       [ 223.94999695,  177.24000549,  247.74000549,  409.05999756,\n",
       "         681.85998535],\n",
       "       [ 220.82000732,  174.52999878,  246.5       ,  407.23999023,\n",
       "         674.        ],\n",
       "       [ 218.91999817,  177.49000549,  247.13000488,  408.20001221,\n",
       "         676.86999512],\n",
       "       [ 221.46000671,  180.1000061 ,  244.80999756,  415.5       ,\n",
       "         677.46002197],\n",
       "       [ 222.5       ,  184.80000305,  251.38999939,  423.30999756,\n",
       "         684.91998291],\n",
       "       [ 223.58000183,  187.        ,  252.53999329,  425.82998657,\n",
       "         680.01000977],\n",
       "       [ 216.53999329,  185.28999329,  254.57000732,  430.6000061 ,\n",
       "         700.        ],\n",
       "       [ 215.75      ,  186.8500061 ,  258.72000122,  440.23001099,\n",
       "         700.82000732],\n",
       "       [ 217.55000305,  186.44999695,  256.        ,  435.        ,\n",
       "         707.54998779],\n",
       "       [ 224.99000549,  190.03999329,  260.72000122,  441.23001099,\n",
       "         705.        ],\n",
       "       [ 229.97000122,  190.22999573,  266.01000977,  437.22000122,\n",
       "         705.54998779],\n",
       "       [ 227.33999634,  191.63999939,  267.25      ,  434.27999878,\n",
       "         702.39001465],\n",
       "       [ 228.6499939 ,  194.27000427,  269.82998657,  433.        ,\n",
       "         706.63000488],\n",
       "       [ 224.92999268,  193.75      ,  270.45001221,  429.82998657,\n",
       "         721.        ],\n",
       "       [ 227.30000305,  194.30999756,  276.13000488,  435.08999634,\n",
       "         724.72998047],\n",
       "       [ 228.46000671,  190.67999268,  276.26000977,  431.51998901,\n",
       "         708.35998535],\n",
       "       [ 230.03999329,  187.13999939,  273.95001221,  428.20999146,\n",
       "         707.        ],\n",
       "       [ 229.52000427,  184.8999939 ,  274.14001465,  428.45001221,\n",
       "         713.64001465],\n",
       "       [ 225.88999939,  184.44000244,  273.72000122,  422.57998657,\n",
       "         706.13000488],\n",
       "       [ 225.13999939,  183.05000305,  278.98999023,  417.63000488,\n",
       "         704.26000977],\n",
       "       [ 227.8999939 ,  185.75      ,  283.85998535,  418.23999023,\n",
       "         713.32000732],\n",
       "       [ 224.5       ,  182.94999695,  286.57998657,  416.        ,\n",
       "         714.76000977],\n",
       "       [ 224.30000305,  181.91999817,  286.        ,  410.8999939 ,\n",
       "         703.88000488],\n",
       "       [ 225.22999573,  182.82000732,  290.82000732,  415.85998535,\n",
       "         719.25      ],\n",
       "       [ 227.77999878,  187.13000488,  287.92001343,  415.23001099,\n",
       "         723.28997803],\n",
       "       [ 229.30000305,  186.63000488,  289.20999146,  416.14001465,\n",
       "         734.90002441],\n",
       "       [ 228.69999695,  189.77999878,  289.92001343,  417.76998901,\n",
       "         725.        ],\n",
       "       [ 233.61000061,  187.63000488,  293.45999146,  422.17999268,\n",
       "         712.51000977],\n",
       "       [ 231.6000061 ,  187.05000305,  287.54998779,  415.17001343,\n",
       "         703.42999268],\n",
       "       [ 233.42999268,  188.22000122,  291.95999146,  422.35998535,\n",
       "         704.34997559],\n",
       "       [ 236.17999268,  187.1499939 ,  292.04000854,  417.14001465,\n",
       "         737.64001465],\n",
       "       [ 234.44999695,  188.05000305,  289.        ,  416.11999512,\n",
       "         765.76000977],\n",
       "       [ 233.88999939,  188.3500061 ,  289.75      ,  418.48999023,\n",
       "         765.27001953],\n",
       "       [ 234.08000183,  188.8500061 ,  287.73001099,  430.85998535,\n",
       "         762.83001709],\n",
       "       [ 229.97999573,  185.25      ,  286.55999756,  425.32998657,\n",
       "         751.9699707 ],\n",
       "       [ 229.74000549,  187.8500061 ,  290.        ,  426.76000977,\n",
       "         756.16998291],\n",
       "       [ 233.32000732,  189.57000732,  293.6000061 ,  431.66000366,\n",
       "         758.67999268],\n",
       "       [ 233.1000061 ,  188.58000183,  294.        ,  428.        ,\n",
       "         751.13000488],\n",
       "       [ 232.61000061,  194.69999695,  297.07000732,  437.44000244,\n",
       "         758.08001709],\n",
       "       [ 229.33999634,  190.50999451,  292.6000061 ,  415.35998535,\n",
       "         753.92999268],\n",
       "       [ 220.97000122,  199.        ,  290.23001099,  409.01000977,\n",
       "         753.47998047],\n",
       "       [ 220.99000549,  196.44999695,  297.98999023,  409.79998779,\n",
       "         753.14001465],\n",
       "       [ 221.80000305,  196.03999329,  297.44000244,  408.36999512,\n",
       "         757.34997559],\n",
       "       [ 222.61000061,  200.00999451,  305.        ,  412.42001343,\n",
       "         771.5       ],\n",
       "       [ 224.63000488,  207.44000244,  307.5       ,  421.27999878,\n",
       "         781.36999512],\n",
       "       [ 227.16999817,  209.72000122,  310.02999878,  425.32000732,\n",
       "         797.35998535],\n",
       "       [ 225.        ,  208.5       ,  325.25      ,  422.51998901,\n",
       "         795.90002441],\n",
       "       [ 224.55000305,  208.36999512,  339.29000854,  418.25      ,\n",
       "         807.5       ],\n",
       "       [ 224.00999451,  209.3999939 ,  345.5       ,  421.64001465,\n",
       "         822.61999512],\n",
       "       [ 225.02000427,  214.16000366,  342.44000244,  425.        ,\n",
       "         833.66998291],\n",
       "       [ 226.3999939 ,  206.75999451,  326.92999268,  419.82000732,\n",
       "         832.03997803],\n",
       "       [ 225.25      ,  204.1499939 ,  327.        ,  414.86999512,\n",
       "         815.5       ],\n",
       "       [ 226.97999573,  199.33000183,  319.        ,  413.10998535,\n",
       "         839.75      ],\n",
       "       [ 228.05999756,  202.97999573,  325.29000854,  416.86999512,\n",
       "         879.97998047],\n",
       "       [ 228.88000488,  203.49000549,  331.3500061 ,  419.5       ,\n",
       "         883.92999268],\n",
       "       [ 228.05999756,  198.25      ,  338.95001221,  411.36999512,\n",
       "         896.        ],\n",
       "       [ 231.46000671,  199.27999878,  345.        ,  418.38000488,\n",
       "         902.04998779],\n",
       "       [ 233.33000183,  201.8999939 ,  341.98001099,  419.58999634,\n",
       "         867.48999023],\n",
       "       [ 234.47000122,  206.97999573,  336.45999146,  425.10998535,\n",
       "         872.05999756],\n",
       "       [ 234.80999756,  205.83000183,  329.33999634,  420.08999634,\n",
       "         882.16998291],\n",
       "       [ 237.27000427,  209.96000671,  332.        ,  421.57000732,\n",
       "         887.51000977],\n",
       "       [ 239.80999756,  210.30999756,  327.3999939 ,  429.83999634,\n",
       "         894.35998535],\n",
       "       [ 242.86999512,  215.96000671,  366.80999756,  433.02999878,\n",
       "         898.04998779],\n",
       "       [ 243.99000549,  218.02999878,  360.77999878,  437.92001343,\n",
       "         917.84997559],\n",
       "       [ 242.91000366,  220.75      ,  364.98999023,  442.29998779,\n",
       "         915.22998047],\n",
       "       [ 241.83000183,  227.21000671,  361.70001221,  442.6000061 ,\n",
       "         928.        ],\n",
       "       [ 246.88999939,  226.08999634,  351.3500061 ,  444.39001465,\n",
       "         913.76000977],\n",
       "       [ 247.96000671,  226.41000366,  353.48999023,  444.04998779,\n",
       "         924.71002197],\n",
       "       [ 246.88999939,  229.83000183,  355.        ,  449.10998535,\n",
       "         933.34997559],\n",
       "       [ 247.82000732,  228.3999939 ,  364.        ,  448.44000244,\n",
       "         916.80999756],\n",
       "       [ 247.99000549,  230.22999573,  350.77999878,  447.26998901,\n",
       "         923.94000244],\n",
       "       [ 250.08000183,  232.38999939,  356.8999939 ,  451.01000977,\n",
       "         921.53997803],\n",
       "       [ 252.16000366,  230.77000427,  354.5       ,  451.32000732,\n",
       "         919.13000488],\n",
       "       [ 247.5       ,  224.91000366,  341.70001221,  441.61999512,\n",
       "         908.17999268],\n",
       "       [ 248.03999329,  219.83999634,  332.73999023,  433.10998535,\n",
       "         893.21002197],\n",
       "       [ 254.77000427,  225.00999451,  342.25      ,  436.73999023,\n",
       "         913.41998291],\n",
       "       [ 255.49000549,  226.94000244,  343.        ,  434.6499939 ,\n",
       "         915.        ],\n",
       "       [ 258.19000244,  228.5       ,  344.88000488,  439.07998657,\n",
       "         928.40002441],\n",
       "       [ 257.82998657,  225.6000061 ,  340.3500061 ,  434.6000061 ,\n",
       "         916.01000977],\n",
       "       [ 252.22999573,  220.05999756,  333.47000122,  426.05999756,\n",
       "         894.51000977],\n",
       "       [ 252.44000244,  222.97000122,  336.26998901,  426.1000061 ,\n",
       "         901.79998779],\n",
       "       [ 248.92999268,  222.02999878,  336.30999756,  425.52999878,\n",
       "         895.5       ],\n",
       "       [ 243.36000061,  222.50999451,  332.1000061 ,  421.07998657,\n",
       "         893.13000488],\n",
       "       [ 244.30999756,  226.77999878,  334.01998901,  428.        ,\n",
       "         888.76000977],\n",
       "       [ 242.97999573,  227.8999939 ,  330.5       ,  429.        ,\n",
       "         879.38000488],\n",
       "       [ 241.91999817,  223.19000244,  327.73999023,  423.45999146,\n",
       "         880.        ],\n",
       "       [ 240.00999451,  221.46000671,  322.76998901,  424.63000488,\n",
       "         866.40002441],\n",
       "       [ 233.52999878,  218.05999756,  314.6000061 ,  415.23999023,\n",
       "         831.5300293 ],\n",
       "       [ 234.75      ,  220.44000244,  325.        ,  417.80999756,\n",
       "         843.20001221],\n",
       "       [ 234.63999939,  222.83000183,  329.88000488,  419.13000488,\n",
       "         836.44000244],\n",
       "       [ 237.3500061 ,  224.41999817,  322.94000244,  428.70001221,\n",
       "         860.96002197],\n",
       "       [ 232.11999512,  225.83999634,  328.72000122,  434.08999634,\n",
       "         859.78997803],\n",
       "       [ 224.        ,  228.8999939 ,  329.3999939 ,  430.20001221,\n",
       "         863.5300293 ],\n",
       "       [ 219.78999329,  232.02000427,  331.25      ,  437.55999756,\n",
       "         998.0300293 ],\n",
       "       [ 224.74000549,  234.1000061 ,  332.32998657,  442.        ,\n",
       "         957.80999756],\n",
       "       [ 224.77999878,  234.5       ,  336.29998779,  445.16000366,\n",
       "         984.40997314],\n",
       "       [ 224.02000427,  226.21000671,  332.35998535,  424.01000977,\n",
       "         971.09997559],\n",
       "       [ 230.8500061 ,  234.28999329,  354.76998901,  434.6000061 ,\n",
       "         966.71002197],\n",
       "       [ 234.11999512,  239.02000427,  358.76000977,  446.69000244,\n",
       "         980.        ],\n",
       "       [ 238.66999817,  237.13999939,  340.8999939 ,  418.76998901,\n",
       "         986.75      ],\n",
       "       [ 247.19000244,  236.5       ,  348.        ,  418.98001099,\n",
       "         974.        ],\n",
       "       [ 229.99000549,  234.05999756,  335.97000122,  411.6000061 ,\n",
       "         973.        ],\n",
       "       [ 227.25      ,  239.00999451,  345.61999512,  412.69000244,\n",
       "         980.4699707 ],\n",
       "       [ 228.52999878,  237.02000427,  345.72000122,  412.3500061 ,\n",
       "         987.72998047],\n",
       "       [ 231.28999329,  238.00999451,  337.48001099,  414.        ,\n",
       "        1007.86999512],\n",
       "       [ 232.6000061 ,  232.5       ,  332.        ,  416.48001099,\n",
       "        1017.        ],\n",
       "       [ 229.57000732,  230.55000305,  327.92001343,  413.70999146,\n",
       "        1023.04998779],\n",
       "       [ 228.19999695,  231.91999817,  324.01998901,  409.64001465,\n",
       "        1020.78997803],\n",
       "       [ 231.19999695,  230.46000671,  319.54998779,  407.20999146,\n",
       "        1005.48999023],\n",
       "       [ 236.91000366,  228.8500061 ,  326.20001221,  407.        ,\n",
       "        1026.63000488],\n",
       "       [ 241.25      ,  229.19999695,  328.02999878,  407.79000854,\n",
       "        1044.94995117],\n",
       "       [ 244.1499939 ,  228.82000732,  328.58999634,  408.        ,\n",
       "        1060.        ],\n",
       "       [ 244.66000366,  225.52000427,  329.73999023,  407.88000488,\n",
       "        1035.18005371],\n",
       "       [ 244.94000244,  224.77999878,  322.23999023,  415.29000854,\n",
       "        1042.        ],\n",
       "       [ 245.94999695,  223.27999878,  318.97000122,  417.33999634,\n",
       "        1029.42004395],\n",
       "       [ 244.92999268,  217.44999695,  311.51000977,  408.51000977,\n",
       "        1008.        ],\n",
       "       [ 248.        ,  211.63000488,  306.25      ,  401.1000061 ,\n",
       "         989.40002441],\n",
       "       [ 244.33000183,  214.94000244,  312.66000366,  398.01000977,\n",
       "         977.59997559]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the function to training and trade\n",
    "StockData = process_df_for_mvo(train)\n",
    "TradeData = process_df_for_mvo(trade)\n",
    "\n",
    "# Converts TradeData to a numpy array\n",
    "TradeData.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean returns of assets in k-portfolio 1\n",
      " [0.055 0.05  0.065 0.071 0.13 ]\n",
      "Variance-Covariance matrix of returns\n",
      " [[3.042 2.356 1.884 1.843 2.037]\n",
      " [2.356 5.98  3.237 2.787 2.975]\n",
      " [1.884 3.237 6.1   2.237 2.447]\n",
      " [1.843 2.787 2.237 2.997 2.038]\n",
      " [2.037 2.975 2.447 2.038 8.125]]\n"
     ]
    }
   ],
   "source": [
    "# Calculates returns per asset\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols] = arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "# Calculates average returns and the covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "# Sets precision for printing results.\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "# Displays average returns and the covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we use PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Mar 26 09:04:33 PM: Encountered unexpected exception importing solver ECOS:\n",
      "ImportError(\"dlopen(/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so, 0x0002): tried: '/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (no such file), '/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\")\n",
      "(CVXPY) Mar 26 09:04:33 PM: Encountered unexpected exception importing solver ECOS_BB:\n",
      "ImportError(\"dlopen(/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so, 0x0002): tried: '/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (no such file), '/opt/miniconda3/lib/python3.12/site-packages/_ecos.cpython-312-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\")\n",
      "[ 5436.     0.  1114. 50000. 43450.]\n",
      "[ 24.8     0.      4.291 116.899  68.95 ]\n",
      "                 Mean Var\n",
      "2024-08-01   99256.126281\n",
      "2024-08-02   97534.227504\n",
      "2024-08-05   91904.120491\n",
      "2024-08-06   94298.113186\n",
      "2024-08-07   96419.596963\n",
      "...                   ...\n",
      "2025-02-20  127849.788793\n",
      "2025-02-21  127233.063667\n",
      "2025-02-24  124666.636866\n",
      "2025-02-25  122571.521042\n",
      "2025-02-26  121333.181784\n",
      "\n",
      "[143 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading the EfficientFrontier class from the PyPortfolioOpt library\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "# Initializing the EfficientFrontier object with average returns and the covariance matrix of returns\n",
    "# Weight constraints are set so that no asset can constitute more than 50% of the portfolio\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "\n",
    "# Calculating raw weights for the maximum Sharpe ratio\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "\n",
    "# Cleaning weights to round very small weights to 0 and normalize the others\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "\n",
    "# Converting cleaned weights to actual investment amounts, assuming an initial capital of 1,000,000\n",
    "mvo_weights = np.array([100000 * cleaned_weights_mean[i] for i in range(5)])\n",
    "print(mvo_weights)\n",
    "\n",
    "# Calculating the last stock price in the dataset to determine the initial quantities of stocks.\n",
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "\n",
    "# Calculating the initial portfolio by multiplying the investment amounts with the last price.\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "print(Initial_Portfolio)\n",
    "\n",
    "# Calculating the portfolio value using trade data and initial stock quantities.\n",
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "\n",
    "# Creating a DataFrame with the results of the mean-variance optimization.\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "print(MVO_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. DJI index for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (144, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_dji = YahooDownloader(start_date = TRADE_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = ['^DJI']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dji = df_dji[['date','close']]\n",
    "fst_day = df_dji['close'][0]\n",
    "dji = pd.merge(df_dji['date'], df_dji['close'].div(fst_day).mul(100000), \n",
    "               how='outer', left_index=True, right_index=True).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Running the backtesting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_22359/3791775406.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  result = pd.merge(result, dji, how='outer', left_index=True, right_index=True).fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# Setting the index of the DataFrames for account values for each of the DRL strategies, if selected.\n",
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0]) if if_using_a2c else None\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0]) if if_using_ddpg else None\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0]) if if_using_ppo else None\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0]) if if_using_td3 else None\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0]) if if_using_sac else None\n",
    "\n",
    "# Creating an empty DataFrame for results.\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# Merging the results of all DRL strategies into one DataFrame, if selected.\n",
    "if if_using_a2c: result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "if if_using_ddpg: result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_ppo: result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_td3: result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_sac: result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "# Merging the mean-variance optimization results and the DJIA index with the main results.\n",
    "result = pd.merge(result, MVO_result, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, dji, how='outer', left_index=True, right_index=True).fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names based on selected strategies.\n",
    "col_name = []\n",
    "col_name.append('A2C') if if_using_a2c else None\n",
    "col_name.append('DDPG') if if_using_ddpg else None\n",
    "col_name.append('PPO') if if_using_ppo else None\n",
    "col_name.append('TD3') if if_using_td3 else None\n",
    "col_name.append('SAC') if if_using_sac else None\n",
    "col_name.append('Mean Var')\n",
    "col_name.append('DJI') \n",
    "result.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2C</th>\n",
       "      <th>PPO</th>\n",
       "      <th>SAC</th>\n",
       "      <th>Mean Var</th>\n",
       "      <th>DJI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>99256.126281</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>98625.716934</td>\n",
       "      <td>88098.883545</td>\n",
       "      <td>98685.036896</td>\n",
       "      <td>97534.227504</td>\n",
       "      <td>97943.071056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>93052.242477</td>\n",
       "      <td>81477.767090</td>\n",
       "      <td>92527.982483</td>\n",
       "      <td>91904.120491</td>\n",
       "      <td>95452.327131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>95640.609268</td>\n",
       "      <td>85437.767090</td>\n",
       "      <td>96018.438110</td>\n",
       "      <td>94298.113186</td>\n",
       "      <td>94670.322190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>97705.572769</td>\n",
       "      <td>87993.285156</td>\n",
       "      <td>96623.399811</td>\n",
       "      <td>96419.596963</td>\n",
       "      <td>95877.330439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      A2C            PPO            SAC      Mean Var  \\\n",
       "date                                                                    \n",
       "2024-08-01  100000.000000  100000.000000  100000.000000  99256.126281   \n",
       "2024-08-02   98625.716934   88098.883545   98685.036896  97534.227504   \n",
       "2024-08-05   93052.242477   81477.767090   92527.982483  91904.120491   \n",
       "2024-08-06   95640.609268   85437.767090   96018.438110  94298.113186   \n",
       "2024-08-07   97705.572769   87993.285156   96623.399811  96419.596963   \n",
       "\n",
       "                      DJI  \n",
       "date                       \n",
       "2024-08-01  100000.000000  \n",
       "2024-08-02   97943.071056  \n",
       "2024-08-05   95452.327131  \n",
       "2024-08-06   94670.322190  \n",
       "2024-08-07   95877.330439  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we plot a graph that shows the total portfolio value over time for each strategy and the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the figure size for the plots and drawing the performance charts of the trading strategies.\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n",
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_22359/3649623815.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n",
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_22359/3649623815.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n",
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_22359/3649623815.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n",
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_22359/3649623815.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n"
     ]
    }
   ],
   "source": [
    "from pyfolio import timeseries\n",
    "import pandas as pd\n",
    "\n",
    "# List of strategies for which you want to generate statistics\n",
    "strategies = ['A2C', 'DDPG', 'PPO', 'TD3', 'SAC', \"Mean Var\", \"DJI\"]\n",
    "\n",
    "for strategy in strategies:\n",
    "    column_name = f'{strategy}'\n",
    "    if column_name in result.columns:\n",
    "        # Calculating daily returns from portfolio values\n",
    "        result[f'{strategy}_returns'] = result[column_name].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2C</th>\n",
       "      <th>PPO</th>\n",
       "      <th>SAC</th>\n",
       "      <th>Mean Var</th>\n",
       "      <th>DJI</th>\n",
       "      <th>A2C_returns</th>\n",
       "      <th>PPO_returns</th>\n",
       "      <th>SAC_returns</th>\n",
       "      <th>Mean Var_returns</th>\n",
       "      <th>DJI_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>99256.126281</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>98625.716934</td>\n",
       "      <td>88098.883545</td>\n",
       "      <td>98685.036896</td>\n",
       "      <td>97534.227504</td>\n",
       "      <td>97943.071056</td>\n",
       "      <td>-0.013743</td>\n",
       "      <td>-0.119011</td>\n",
       "      <td>-0.013150</td>\n",
       "      <td>-0.017348</td>\n",
       "      <td>-0.020569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>93052.242477</td>\n",
       "      <td>81477.767090</td>\n",
       "      <td>92527.982483</td>\n",
       "      <td>91904.120491</td>\n",
       "      <td>95452.327131</td>\n",
       "      <td>-0.056511</td>\n",
       "      <td>-0.075156</td>\n",
       "      <td>-0.062391</td>\n",
       "      <td>-0.057724</td>\n",
       "      <td>-0.025431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>95640.609268</td>\n",
       "      <td>85437.767090</td>\n",
       "      <td>96018.438110</td>\n",
       "      <td>94298.113186</td>\n",
       "      <td>94670.322190</td>\n",
       "      <td>0.027816</td>\n",
       "      <td>0.048602</td>\n",
       "      <td>0.037723</td>\n",
       "      <td>0.026049</td>\n",
       "      <td>-0.008193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>97705.572769</td>\n",
       "      <td>87993.285156</td>\n",
       "      <td>96623.399811</td>\n",
       "      <td>96419.596963</td>\n",
       "      <td>95877.330439</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.029911</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.012750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      A2C            PPO            SAC      Mean Var  \\\n",
       "date                                                                    \n",
       "2024-08-01  100000.000000  100000.000000  100000.000000  99256.126281   \n",
       "2024-08-02   98625.716934   88098.883545   98685.036896  97534.227504   \n",
       "2024-08-05   93052.242477   81477.767090   92527.982483  91904.120491   \n",
       "2024-08-06   95640.609268   85437.767090   96018.438110  94298.113186   \n",
       "2024-08-07   97705.572769   87993.285156   96623.399811  96419.596963   \n",
       "\n",
       "                      DJI  A2C_returns  PPO_returns  SAC_returns  \\\n",
       "date                                                               \n",
       "2024-08-01  100000.000000          NaN          NaN          NaN   \n",
       "2024-08-02   97943.071056    -0.013743    -0.119011    -0.013150   \n",
       "2024-08-05   95452.327131    -0.056511    -0.075156    -0.062391   \n",
       "2024-08-06   94670.322190     0.027816     0.048602     0.037723   \n",
       "2024-08-07   95877.330439     0.021591     0.029911     0.006300   \n",
       "\n",
       "            Mean Var_returns  DJI_returns  \n",
       "date                                       \n",
       "2024-08-01               NaN          NaN  \n",
       "2024-08-02         -0.017348    -0.020569  \n",
       "2024-08-05         -0.057724    -0.025431  \n",
       "2024-08-06          0.026049    -0.008193  \n",
       "2024-08-07          0.022498     0.012750  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculate returns based on the selected strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Strategy Stats (A2C)==============\n",
      "Annual return         -0.083628\n",
      "Cumulative returns    -0.048350\n",
      "Annual volatility      0.235536\n",
      "Sharpe ratio          -0.252279\n",
      "Calmar ratio          -0.708257\n",
      "Stability              0.023406\n",
      "Max drawdown          -0.118076\n",
      "Omega ratio            0.956808\n",
      "Sortino ratio         -0.317148\n",
      "Skew                  -1.204657\n",
      "Kurtosis               3.406911\n",
      "Tail ratio             1.027653\n",
      "Daily value at risk   -0.029911\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Strategija DDPG nije pronaena u rezultatima.\n",
      "\n",
      "==============Strategy Stats (PPO)==============\n",
      "Annual return          0.250855\n",
      "Cumulative returns     0.135432\n",
      "Annual volatility      0.313810\n",
      "Sharpe ratio           0.873256\n",
      "Calmar ratio           1.354347\n",
      "Stability              0.882955\n",
      "Max drawdown          -0.185222\n",
      "Omega ratio            1.170820\n",
      "Sortino ratio          1.138817\n",
      "Skew                  -1.787154\n",
      "Kurtosis               9.495736\n",
      "Tail ratio             1.087703\n",
      "Daily value at risk   -0.038449\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Strategija TD3 nije pronaena u rezultatima.\n",
      "\n",
      "==============Strategy Stats (SAC)==============\n",
      "Annual return          0.471402\n",
      "Cumulative returns     0.245033\n",
      "Annual volatility      0.345340\n",
      "Sharpe ratio           1.288390\n",
      "Calmar ratio           2.856530\n",
      "Stability              0.733041\n",
      "Max drawdown          -0.165026\n",
      "Omega ratio            1.256096\n",
      "Sortino ratio          2.067215\n",
      "Skew                   0.934878\n",
      "Kurtosis               5.897033\n",
      "Tail ratio             1.011703\n",
      "Daily value at risk   -0.041743\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "==============Strategy Stats (Mean Var)==============\n",
      "Annual return          0.424644\n",
      "Cumulative returns     0.222425\n",
      "Annual volatility      0.231906\n",
      "Sharpe ratio           1.641591\n",
      "Calmar ratio           4.603470\n",
      "Stability              0.886657\n",
      "Max drawdown          -0.092244\n",
      "Omega ratio            1.337741\n",
      "Sortino ratio          2.542235\n",
      "Skew                   0.644371\n",
      "Kurtosis               8.160315\n",
      "Tail ratio             0.886388\n",
      "Daily value at risk   -0.027707\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "==============Strategy Stats (DJI)==============\n",
      "Annual return          0.114653\n",
      "Cumulative returns     0.063531\n",
      "Annual volatility      0.122441\n",
      "Sharpe ratio           0.947560\n",
      "Calmar ratio           1.658384\n",
      "Stability              0.678036\n",
      "Max drawdown          -0.069136\n",
      "Omega ratio            1.173267\n",
      "Sortino ratio          1.355521\n",
      "Skew                  -0.326090\n",
      "Kurtosis               1.282800\n",
      "Tail ratio             0.984732\n",
      "Daily value at risk   -0.014966\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We assume that the result DataFrame already contains portfolio values for each strategy\n",
    "for strategy in strategies:\n",
    "    # Check if the strategy exists in the DataFrame\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Extract daily returns for the current strategy\n",
    "        returns = result[f'{strategy}_returns'].dropna()\n",
    "        returns.index = pd.to_datetime(returns.index)\n",
    "\n",
    "        # Calculate performance statistics for the current strategy\n",
    "        perf_stats = timeseries.perf_stats(returns=returns, factor_returns=None, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "        # Print performance statistics\n",
    "        print(f\"==============Strategy Stats ({strategy})==============\")\n",
    "        print(perf_stats)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Strategy {strategy} not found in results.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We plot cumulative returns for each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Setting the figure size for the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterating through each strategy and plotting its cumulative returns\n",
    "for strategy in strategies:\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Make sure dates are properly parsed\n",
    "        result.index = pd.to_datetime(result.index)\n",
    "        \n",
    "        # Extracting daily returns for the current strategy and converting to decimal format if necessary\n",
    "        returns = result[f'{strategy}_returns'].dropna() + 1  # Adds 1 for using cumprod()\n",
    "        \n",
    "        # Calculating cumulative returns and converting to percentage\n",
    "        cumulative_returns = (returns.cumprod() - 1) * 100  # Convert to percentage\n",
    "        \n",
    "        # Plotting cumulative returns with original colors\n",
    "        plt.plot(cumulative_returns.index, cumulative_returns, label=strategy)\n",
    "\n",
    "# Format y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0f}%'.format(y)))\n",
    "plt.ylabel('Cumulative Returns (%)')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "# Format x-axis dates\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Make sure dates are in the correct format and rotated\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Adding title and legend\n",
    "#plt.title('Cumulative Returns of DRL Strategies')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Add grid with light gray color\n",
    "plt.grid(True, linestyle='-', alpha=0.2)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# For ppo\n",
    "with open('results/6. PORTFOLIO/finrl_df_account_value_ppo.pkl', 'wb') as f:\n",
    "    pickle.dump(df_account_value_ppo, f)\n",
    "    \n",
    "# For a2c\n",
    "with open('results/6. PORTFOLIO/finrl_df_account_value_a2c.pkl', 'wb') as f:\n",
    "    pickle.dump(df_account_value_a2c, f)\n",
    "\n",
    "# For sac\n",
    "with open('results/6. PORTFOLIO/finrl_df_account_value_sac.pkl', 'wb') as f:\n",
    "    pickle.dump(df_account_value_sac, f)\n",
    "\n",
    "# For mean var\n",
    "with open('results/6. PORTFOLIO/finrl_mean_var.pkl', 'wb') as f:\n",
    "    pickle.dump(MVO_result, f)\n",
    "\n",
    "# For dji\n",
    "with open('results/6. PORTFOLIO/finrl_dji.pkl', 'wb') as f:\n",
    "    pickle.dump(dji, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
